#!/usr/bin/env python3
"""
Script b·ªï sung crawl d·ªØ li·ªáu c√≤n thi·∫øu:
- Rankings (th·ª≠ nhi·ªÅu ng√†y)
- Historical data (th·ª≠ nhi·ªÅu payload)
- Grid AQI data (t·ª´ WMTS tiles)
"""

import requests
import csv
from datetime import datetime, timedelta
import time

BASE_URL = "https://geoi.com.vn"

def try_rankings_multiple_days(days_back=30):
    """Th·ª≠ l·∫•y rankings cho nhi·ªÅu ng√†y"""
    print("\n" + "="*70)
    print("üèÜ TH·ª¨ L·∫§Y RANKINGS CHO NHI·ªÄU NG√ÄY")
    print("="*70)
    
    url = f"{BASE_URL}/api/componentgeotiffdaily/rankingprovince"
    rankings_found = []
    
    for i in range(days_back):
        date_obj = datetime.now() - timedelta(days=i)
        date_str = date_obj.strftime("%Y-%m-%d")
        date_pre = (date_obj - timedelta(days=1)).strftime("%Y-%m-%d")
        
        payload = {
            "group_id": "satellite_aqi_pm25",
            "component_id": "pm25",
            "date_shooting": date_str,
            "date_shooting_pre": date_pre,
            "lang_id": "vi",
            "province_id": "VNM.27_1"
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            data = response.json()
            
            if data.get('Code') == 200 and data.get('Data'):
                comps = data['Data'].get('comps', [])
                if comps:
                    print(f"  ‚úì {date_str}: {len(comps)} rankings")
                    for rank_data in comps:
                        rankings_found.append({
                            'administrative_id': rank_data.get('administrative_id'),
                            'district_name': rank_data.get('administrative_name'),
                            'rank': rank_data.get('no'),
                            'aqi_avg': rank_data.get('avg'),
                            'aqi_prev': rank_data.get('avg_pre'),
                            'date': date_str
                        })
                    break  # T√¨m ƒë∆∞·ª£c r·ªìi th√¨ d·ª´ng
        except:
            pass
        
        if i % 5 == 0 and i > 0:
            print(f"  ‚Ä¢ ƒê√£ th·ª≠ {i} ng√†y...")
        time.sleep(0.2)
    
    if not rankings_found:
        print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y rankings trong {days_back} ng√†y g·∫ßn ƒë√¢y")
    
    return rankings_found

def try_historical_multiple_methods():
    """Th·ª≠ nhi·ªÅu c√°ch l·∫•y historical data"""
    print("\n" + "="*70)
    print("üìà TH·ª¨ L·∫§Y HISTORICAL DATA")
    print("="*70)
    
    url = f"{BASE_URL}/api/componentgeotiffdaily/identify_province_id_list_geotiff"
    historical_found = []
    
    # Method 1: Province-wide v·ªõi nhi·ªÅu ng√†y
    for days_back in [3, 7, 14, 30]:
        date_str = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        
        payload = {
            "province_id": "VNM.27_1",
            "groupcomponent_id": "63",
            "date_request": date_str,
            "predays": days_back,
            "nextdays": 0,
            "lang_id": "vi"
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            data = response.json()
            
            if data.get('Code') == 200 and data.get('Data'):
                comps = data['Data'].get('comps', [])
                if comps:
                    print(f"  ‚úì Method 1 (predays={days_back}): {len(comps)} records")
                    for comp in comps:
                        historical_found.append({
                            'province_id': 'VNM.27_1',
                            'province_name': 'H√† N·ªôi',
                            'date': comp.get('requestdate'),
                            'pm25_value': comp.get('val'),
                            'aqi_value': comp.get('val_aqi'),
                            'component': comp.get('titlecomponent', 'PM2.5')
                        })
                    break
        except:
            pass
        
        time.sleep(0.3)
    
    # Method 2: Th·ª≠ v·ªõi date_request c≈© h∆°n
    if not historical_found:
        for days_back in [30, 60, 90]:
            date_str = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")
            
            payload = {
                "province_id": "VNM.27_1",
                "groupcomponent_id": "63",
                "date_request": date_str,
                "predays": 7,
                "nextdays": 0,
                "lang_id": "vi"
            }
            
            try:
                response = requests.post(url, json=payload, timeout=10)
                data = response.json()
                
                if data.get('Code') == 200 and data.get('Data'):
                    comps = data['Data'].get('comps', [])
                    if comps:
                        print(f"  ‚úì Method 2 (date={date_str}): {len(comps)} records")
                        for comp in comps:
                            historical_found.append({
                                'province_id': 'VNM.27_1',
                                'province_name': 'H√† N·ªôi',
                                'date': comp.get('requestdate'),
                                'pm25_value': comp.get('val'),
                                'aqi_value': comp.get('val_aqi'),
                                'component': comp.get('titlecomponent', 'PM2.5')
                            })
                        break
            except:
                pass
            
            time.sleep(0.3)
    
    if not historical_found:
        print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y historical data")
    
    return historical_found

def crawl_grid_aqi_sample():
    """Crawl m·∫´u grid AQI t·ª´ WMTS tiles"""
    print("\n" + "="*70)
    print("üó∫Ô∏è  CRAWL GRID AQI (WMTS TILES) - M·∫™U")
    print("="*70)
    
    try:
        import mapbox_vector_tile
        print("  ‚úì mapbox_vector_tile available")
    except ImportError:
        print("  ‚ö†Ô∏è  C·∫ßn c√†i: pip install mapbox-vector-tile")
        print("  ‚Üí B·ªè qua crawl grid AQI")
        return []
    
    grid_data = []
    
    # Tile covering H√† N·ªôi center (zoom 9)
    tiles_to_crawl = [
        (812, 196, 9),  # C·∫ßu Gi·∫•y area
        (812, 197, 9),  # ƒê·ªëng ƒêa area
    ]
    
    for tilecol, tilerow, zoom in tiles_to_crawl:
        url = f"{BASE_URL}/geoserver/gwc/service/wmts"
        params = {
            "REQUEST": "GetTile",
            "SERVICE": "WMTS",
            "VERSION": "1.0.0",
            "LAYER": "hydroalp:gis_a_station_days_aqi_pm25",
            "STYLE": "",
            "TILEMATRIX": f"EPSG:4326:{zoom}",
            "TILEMATRIXSET": "EPSG:4326",
            "FORMAT": "application/vnd.mapbox-vector-tile",
            "TILECOL": str(tilecol),
            "TILEROW": str(tilerow)
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                tile_data = mapbox_vector_tile.decode(response.content)
                
                for layer_name, layer_data in tile_data.items():
                    features = layer_data.get('features', [])
                    print(f"  ‚úì Tile ({tilecol},{tilerow}): {len(features)} features")
                    
                    # L·∫•y 20 features ƒë·∫ßu m·ªói tile
                    for feature in features[:20]:
                        props = feature.get('properties', {})
                        grid_data.append({
                            'latitude': props.get('coor_y'),
                            'longitude': props.get('coor_x'),
                            'aqi_pm25': props.get('aqi_pm25'),
                            'measurement_time': props.get('datetime_shooting'),
                            'parent_id': props.get('parent_id'),
                            'group_id': props.get('group_id'),
                            'oid': props.get('oid')
                        })
        except Exception as e:
            print(f"  ‚úó Tile ({tilecol},{tilerow}): {e}")
        
        time.sleep(0.3)
    
    print(f"  ‚Üí T·ªïng: {len(grid_data)} grid points")
    return grid_data

def save_supplemental_data(rankings, historical, grid_data):
    """L∆∞u d·ªØ li·ªáu b·ªï sung"""
    files = []
    
    if rankings:
        filename = 'rankings_supplemental.csv'
        fieldnames = ['administrative_id', 'district_name', 'rank', 'aqi_avg', 'aqi_prev', 'date']
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rankings)
        files.append(f"{filename} ({len(rankings)} rows)")
    
    if historical:
        filename = 'historical_supplemental.csv'
        fieldnames = ['province_id', 'province_name', 'date', 'pm25_value', 'aqi_value', 'component']
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(historical)
        files.append(f"{filename} ({len(historical)} rows)")
    
    if grid_data:
        filename = 'grid_aqi_supplemental.csv'
        fieldnames = ['latitude', 'longitude', 'aqi_pm25', 'measurement_time', 'parent_id', 'group_id', 'oid']
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(grid_data)
        files.append(f"{filename} ({len(grid_data)} rows)")
    
    return files

def main():
    print("\n" + "="*70)
    print("üîß CRAWL D·ªÆ LI·ªÜU B·ªî SUNG")
    print("="*70)
    
    # 1. Rankings
    rankings = try_rankings_multiple_days(days_back=30)
    
    # 2. Historical
    historical = try_historical_multiple_methods()
    
    # 3. Grid AQI
    grid_data = crawl_grid_aqi_sample()
    
    # Save
    if rankings or historical or grid_data:
        print("\n" + "="*70)
        print("üíæ L∆∞u d·ªØ li·ªáu...")
        print("="*70)
        files = save_supplemental_data(rankings, historical, grid_data)
        
        print("\n‚úÖ Ho√†n th√†nh!")
        print(f"üìÅ Files:")
        for f in files:
            print(f"   ‚Ä¢ {f}")
    else:
        print("\n‚ö†Ô∏è  Kh√¥ng crawl ƒë∆∞·ª£c d·ªØ li·ªáu b·ªï sung n√†o")
    
    print("="*70 + "\n")

if __name__ == "__main__":
    main()
